{
  "paths": [
    {
      "type": "file",
      "value": "Ami-Chatbot.md"
    },
    {
      "type": "file",
      "value": "CloudHosting.md"
    },
    {
      "type": "file",
      "value": "PhysicalServer.md"
    },
    {
      "type": "file",
      "value": "match_documents.md"
    }
  ],
  "contents": [
    {
      "path": "Ami-Chatbot.md",
      "url": "Ami-Chatbot.html",
      "content": "---\nid: Ami-Chatbot\naliases:\n  - AI Chatbot\ntags: []\nobsius: https://obsius.site/6o343f6t6e435s5i5n5a\n---\n\n> [!WARNING]\n> Web scraping [AMDSB Polices and Procedures web page](https://www.amdsb.ca/apps/pages/policiesprocedures)\n> edlio, our website provider, has Cloudflare anti-web scraping enabled on our Admin Procedure URLs.\n> May need to download every AP manually, and map out the links separately.\n\n> [!TODO]\n>\n> - [ ] Map out link paths of The Core Navigation bar\n> - [ ] Figure out how AMDSB main website and school sites would be scraped\n> - [ ] Flush out the `System Template` for Ami to reply with better information on paths and links\n\n## Files that may not want to be given to the AI\n\nThese files may expose too much contact information such as Jason, Andrea, Kenneth, Jane, Lisa Walsh's (old) phone numbers, etc.\n\n- Under [IT Guidelines](https://amdsb.sharepoint.com/sites/Info/SSS/Documents/Forms/AllItems.aspx?viewpath=%2Fsites%2FInfo%2FSSS%2FDocuments%2FForms%2FAllItems%2Easpx&id=%2Fsites%2FInfo%2FSSS%2FDocuments%2FIT%20Information%20%26%20Resources%2FIT%20Guidelines&viewid=67b932a0%2Dcd43%2D4b96%2Db390%2Da8f723df8543)\n  - [15_AMDSB Cyber Incident Repsonse plan](https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/15_AMDSB%20Cyber%20Incident%20Reponse%20Plan.pdf?csf=1&web=1&e=g2jRie)\n  - [16_AMDSB Vulnerability and Patch Management](https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/16_AMDSB%20Vulnerability%20and%20Patch%20Management%20Guidelines.pdf?csf=1&web=1&e=i4Rq8a)\n  - [17_AMDSB Disaster Recovery Plan](https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/17_AMDSB%20Disaster%20Recovery%20Plan.pdf?csf=1&web=1&e=CBewQd)\n\n# How are we going to host it?\n\n1.  [Physical Server](PhysicalServer.md)\n2.  [Cloud Hosting](CloudHosting.md)\n\n---\n\n## **Current Conclusion**\n\nDue to the cost of Cloud Hosting overtime, but it's advantages to scale up and down during initial testing:\n\n#### 1. I believe that it is necessary to start with a g4dn.xlarge instance at AWS.\n\n- Scale up and down testing out dozens of people sending in prompts and check the time to respond and usage resources.\n- Technically, hundreds of people could be using Ami at a single time and scaling to the needed amount of instances/ GPUs is imperative for adequate up-time.\n\n#### 2. Once we realize our needs we buy physical machines\n\n- This is more cost effective in the long run. (2+ years)\n- One physical machine could be enough if it is powerful enough. (enough VRAM, decent CPU, enough RAM)\n- The vector database could run off of the one machine that has enough ram. A VM could suffice with current estimates.\n\n##### It could be totally possible that this less intense usage of AI, a chatbot, could be run fully on one powerful enough machine.\n\n- One powerful machine would be slower than two slightly slower machines.\n  - This is because one GPU can only, realistically, send one response at a time.\n  - e.g. 1 x 24GB VRAM 4090 vs 2 x 16GB VRAM 3080s\n",
      "html": "<hr>\n<p>id: Ami-Chatbot\naliases:</p>\n<ul>\n<li>AI Chatbot\ntags: []\nobsius: <a href=\"https://obsius.site/6o343f6t6e435s5i5n5a\">https://obsius.site/6o343f6t6e435s5i5n5a</a></li>\n</ul>\n<hr>\n<blockquote>\n<p>[!WARNING]\nWeb scraping <a href=\"https://www.amdsb.ca/apps/pages/policiesprocedures\">AMDSB Polices and Procedures web page</a>\nedlio, our website provider, has Cloudflare anti-web scraping enabled on our Admin Procedure URLs.\nMay need to download every AP manually, and map out the links separately.</p>\n</blockquote>\n<blockquote>\n<p>[!TODO]</p>\n<ul>\n<li>[ ] Map out link paths of The Core Navigation bar</li>\n<li>[ ] Figure out how AMDSB main website and school sites would be scraped</li>\n<li>[ ] Flush out the <code>System Template</code> for Ami to reply with better information on paths and links</li>\n</ul>\n</blockquote>\n<h2 id=\"files-that-may-not-want-to-be-given-to-the-ai\">Files that may not want to be given to the AI <a class=\"heading-anchor-permalink\" href=\"#files-that-may-not-want-to-be-given-to-the-ai\">#</a></h2>\n<p>These files may expose too much contact information such as Jason, Andrea, Kenneth, Jane, Lisa Walsh’s (old) phone numbers, etc.</p>\n<ul>\n<li>Under <a href=\"https://amdsb.sharepoint.com/sites/Info/SSS/Documents/Forms/AllItems.aspx?viewpath=%2Fsites%2FInfo%2FSSS%2FDocuments%2FForms%2FAllItems%2Easpx&amp;id=%2Fsites%2FInfo%2FSSS%2FDocuments%2FIT%20Information%20%26%20Resources%2FIT%20Guidelines&amp;viewid=67b932a0%2Dcd43%2D4b96%2Db390%2Da8f723df8543\">IT Guidelines</a>\n<ul>\n<li><a href=\"https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/15_AMDSB%20Cyber%20Incident%20Reponse%20Plan.pdf?csf=1&amp;web=1&amp;e=g2jRie\">15_AMDSB Cyber Incident Repsonse plan</a></li>\n<li><a href=\"https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/16_AMDSB%20Vulnerability%20and%20Patch%20Management%20Guidelines.pdf?csf=1&amp;web=1&amp;e=i4Rq8a\">16_AMDSB Vulnerability and Patch Management</a></li>\n<li><a href=\"https://amdsb.sharepoint.com/:b:/r/sites/Info/SSS/Documents/IT%20Information%20%26%20Resources/IT%20Guidelines/17_AMDSB%20Disaster%20Recovery%20Plan.pdf?csf=1&amp;web=1&amp;e=CBewQd\">17_AMDSB Disaster Recovery Plan</a></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"how-are-we-going-to-host-it%3F\">How are we going to host it? <a class=\"heading-anchor-permalink\" href=\"#how-are-we-going-to-host-it%3F\">#</a></h1>\n<ol>\n<li><a href=\"PhysicalServer.html\">Physical Server</a></li>\n<li><a href=\"CloudHosting.html\">Cloud Hosting</a></li>\n</ol>\n<hr>\n<h2 id=\"current-conclusion\"><strong>Current Conclusion</strong> <a class=\"heading-anchor-permalink\" href=\"#current-conclusion\">#</a></h2>\n<p>Due to the cost of Cloud Hosting overtime, but it’s advantages to scale up and down during initial testing:</p>\n<h4 id=\"1.-i-believe-that-it-is-necessary-to-start-with-a-g4dn.xlarge-instance-at-aws.\">1. I believe that it is necessary to start with a g4dn.xlarge instance at AWS. <a class=\"heading-anchor-permalink\" href=\"#1.-i-believe-that-it-is-necessary-to-start-with-a-g4dn.xlarge-instance-at-aws.\">#</a></h4>\n<ul>\n<li>Scale up and down testing out dozens of people sending in prompts and check the time to respond and usage resources.</li>\n<li>Technically, hundreds of people could be using Ami at a single time and scaling to the needed amount of instances/ GPUs is imperative for adequate up-time.</li>\n</ul>\n<h4 id=\"2.-once-we-realize-our-needs-we-buy-physical-machines\">2. Once we realize our needs we buy physical machines <a class=\"heading-anchor-permalink\" href=\"#2.-once-we-realize-our-needs-we-buy-physical-machines\">#</a></h4>\n<ul>\n<li>This is more cost effective in the long run. (2+ years)</li>\n<li>One physical machine could be enough if it is powerful enough. (enough VRAM, decent CPU, enough RAM)</li>\n<li>The vector database could run off of the one machine that has enough ram. A VM could suffice with current estimates.</li>\n</ul>\n<h5 id=\"it-could-be-totally-possible-that-this-less-intense-usage-of-ai%2C-a-chatbot%2C-could-be-run-fully-on-one-powerful-enough-machine.\">It could be totally possible that this less intense usage of AI, a chatbot, could be run fully on one powerful enough machine. <a class=\"heading-anchor-permalink\" href=\"#it-could-be-totally-possible-that-this-less-intense-usage-of-ai%2C-a-chatbot%2C-could-be-run-fully-on-one-powerful-enough-machine.\">#</a></h5>\n<ul>\n<li>One powerful machine would be slower than two slightly slower machines.\n<ul>\n<li>This is because one GPU can only, realistically, send one response at a time.</li>\n<li>e.g. 1 x 24GB VRAM 4090 vs 2 x 16GB VRAM 3080s</li>\n</ul>\n</li>\n</ul>\n",
      "id": 0
    },
    {
      "path": "CloudHosting.md",
      "url": "CloudHosting.html",
      "content": "---\r\nid: CloudHosting\r\naliases:\r\n  - CloudHosting\r\ntags: []\r\n---\r\n\r\n# CloudHosting\r\n\r\n[Instances.vantages.sh - Site for comparing/ looking at instances quickly](https://instances.vantage.sh/)\r\n\r\n---\r\n\r\n### Cons\r\n\r\n- Overtime this will cost more money\r\n\r\n### Pros\r\n\r\n- Scaling if needed is simple and can be automatic\r\n\r\n---\r\n\r\n### <u>AWS Solution</u>\r\n\r\n> [!TIP]\r\n>\r\n> ## Starting out, the entry level AWS EC2 instance is [g4dn.xlarge](https://instances.vantage.sh/aws/ec2/g4dn.xlarge)\r\n>\r\n> - It offers 1 Nvidia Tensor Code (16GBs of VRAM), 16GBs of RAM, and 4 vCPUs.\r\n> - The On Demand pricing is $0.5840USD per hour ($426.32 per month/ $5115.84USD per year)\r\n> - The 1 Year reserve is $0.3680USD per hour ($268.64USD per month/ $3223.68USD per year)\r\n\r\nThe [g4dn.12xlarge](https://instances.vantage.sh/aws/ec2/g4dn.12xlarge?region=ca-central-1&os=linux&cost_duration=annually&reserved_term=Standard.noUpfront) offers considerable more power.\r\n\r\n- It offers 4 of the same GPUs, 192GBs of RAM, and 48 vCPUs\r\n- On Demand pricing is $38,044USD per year\r\n- 1 year reserved is $23,967USD per year\r\n\r\n---\r\n\r\n### <u>Azure Solution</u>\r\n\r\n> [!TIP]\r\n>\r\n> ## Starting out, entry level Azure VM is the NC4as T4 v3\r\n>\r\n> - This is similar to the AWS g4dn.xlarge instance.\r\n> - Offers the a T4 GPU, 16GB of VRAM, 28GBs of RAM, and 4 vCPUs\r\n\r\n### <u>Other Solutions:</u>\r\n\r\n#### [LambdaLabs](https://lambdalabs.com/)\r\n\r\n#### [Vast](https://vast.ai/)\r\n",
      "html": "<hr>\n<p>id: CloudHosting\naliases:</p>\n<ul>\n<li>CloudHosting\ntags: []</li>\n</ul>\n<hr>\n<h1 id=\"cloudhosting\">CloudHosting <a class=\"heading-anchor-permalink\" href=\"#cloudhosting\">#</a></h1>\n<p><a href=\"https://instances.vantage.sh/\">Instances.vantages.sh - Site for comparing/ looking at instances quickly</a></p>\n<hr>\n<h3 id=\"cons\">Cons <a class=\"heading-anchor-permalink\" href=\"#cons\">#</a></h3>\n<ul>\n<li>Overtime this will cost more money</li>\n</ul>\n<h3 id=\"pros\">Pros <a class=\"heading-anchor-permalink\" href=\"#pros\">#</a></h3>\n<ul>\n<li>Scaling if needed is simple and can be automatic</li>\n</ul>\n<hr>\n<h3 id=\"aws-solution\"><u>AWS Solution</u> <a class=\"heading-anchor-permalink\" href=\"#aws-solution\">#</a></h3>\n<blockquote>\n<p>[!TIP]</p>\n<h2 id=\"starting-out%2C-the-entry-level-aws-ec2-instance-is-g4dn.xlarge\">Starting out, the entry level AWS EC2 instance is <a href=\"https://instances.vantage.sh/aws/ec2/g4dn.xlarge\">g4dn.xlarge</a> <a class=\"heading-anchor-permalink\" href=\"#starting-out%2C-the-entry-level-aws-ec2-instance-is-g4dn.xlarge\">#</a></h2>\n<ul>\n<li>It offers 1 Nvidia Tensor Code (16GBs of VRAM), 16GBs of RAM, and 4 vCPUs.</li>\n<li>The On Demand pricing is $0.5840USD per hour ($426.32 per month/ $5115.84USD per year)</li>\n<li>The 1 Year reserve is $0.3680USD per hour ($268.64USD per month/ $3223.68USD per year)</li>\n</ul>\n</blockquote>\n<p>The <a href=\"https://instances.vantage.sh/aws/ec2/g4dn.12xlarge?region=ca-central-1&amp;os=linux&amp;cost_duration=annually&amp;reserved_term=Standard.noUpfront\">g4dn.12xlarge</a> offers considerable more power.</p>\n<ul>\n<li>It offers 4 of the same GPUs, 192GBs of RAM, and 48 vCPUs</li>\n<li>On Demand pricing is $38,044USD per year</li>\n<li>1 year reserved is $23,967USD per year</li>\n</ul>\n<hr>\n<h3 id=\"azure-solution\"><u>Azure Solution</u> <a class=\"heading-anchor-permalink\" href=\"#azure-solution\">#</a></h3>\n<blockquote>\n<p>[!TIP]</p>\n<h2 id=\"starting-out%2C-entry-level-azure-vm-is-the-nc4as-t4-v3\">Starting out, entry level Azure VM is the NC4as T4 v3 <a class=\"heading-anchor-permalink\" href=\"#starting-out%2C-entry-level-azure-vm-is-the-nc4as-t4-v3\">#</a></h2>\n<ul>\n<li>This is similar to the AWS g4dn.xlarge instance.</li>\n<li>Offers the a T4 GPU, 16GB of VRAM, 28GBs of RAM, and 4 vCPUs</li>\n</ul>\n</blockquote>\n<h3 id=\"other-solutions%3A\"><u>Other Solutions:</u> <a class=\"heading-anchor-permalink\" href=\"#other-solutions%3A\">#</a></h3>\n<h4 id=\"lambdalabs\"><a href=\"https://lambdalabs.com/\">LambdaLabs</a> <a class=\"heading-anchor-permalink\" href=\"#lambdalabs\">#</a></h4>\n<h4 id=\"vast\"><a href=\"https://vast.ai/\">Vast</a> <a class=\"heading-anchor-permalink\" href=\"#vast\">#</a></h4>\n",
      "id": 1
    },
    {
      "path": "PhysicalServer.md",
      "url": "PhysicalServer.html",
      "content": "---\nid: 1722880895-TYAB\naliases:\n  - Physical Server\ntags: []\n---\n\n# Physical Server\n\n> [!NOTE]\n>\n> ## 1, singular, decent machine, estimated pricing.\n>\n> CPU: A high-performance multi-core processor, such as an Intel Xeon or AMD EPYC server CPU.\n> Estimated cost: $2,000 - $5,000\n>\n> ---\n>\n> RAM: At least 128GB to 256GB of RAM to handle multiple concurrent sessions.\n> Estimated cost: $1,000 - $2,000\n>\n> ---\n>\n> GPU: A powerful GPU for AI model inference, such as an NVIDIA A100 or A6000.\n> Estimated cost: $5,000 - $10,000\n>\n> ---\n>\n> Storage: Fast SSD storage, at least 1TB-2TB for the operating system, AI models, and data.\n> Estimated cost: $500 - $1,000\n>\n> ---\n>\n> Server chassis and power supply\n> Estimated cost: $1,000 - $2,000\n>\n> ---\n>\n> Total hardware cost estimate: $9,500 - $20,000\n\n---\n\n> [!WARNING]\n> My estimate is that this would be fine for up to 100 people at a time. There would be delay.\n> More people = More delay in response as people would be queued up for the next chance the gpu can process the request.\n>\n> - This means, as a test / first adoption of AI chatbot, one machine would work.\n>   - However, as more use cases and more data is supplied to the chatbot, the more processing power it needs to fulfill the same response times.\n\n> [!important]\n>\n> ## If this is the path taken, there are topics needed to be handled.\n>\n> 1. Load balancing.\n>\n> - If there are multiple machines running the back-end for the chatbot, load balancing will be necessary in order to queue requests\n>\n> 2. Linux is the quickest and most cost effective OS.\n>\n> - Can we handle this with our current security tech stack?\n\nCurrent docker location: `Directory: C:\\Users\\Lochis\\ami-chatbot-db-supabase\\supabase\\docker`\n\nSelf-hosting Vector DB: Supabase\n\n- [Instructions](https://supabase.com/docs/guides/self-hosting/docker)\n\n```bash\n# Stop and remove the containers\n\ndocker compose down\n\n# Recreate and start the containers\n\ndocker compose up -d\n```\n\n[match_documents SQL function for vector similarity search](match_documents.md)\n\n> [!IMPORTANT]\n> Make sure to enable extension: **Vector** in the **Public Schema**\n",
      "html": "<hr>\n<p>id: 1722880895-TYAB\naliases:</p>\n<ul>\n<li>Physical Server\ntags: []</li>\n</ul>\n<hr>\n<h1 id=\"physical-server\">Physical Server <a class=\"heading-anchor-permalink\" href=\"#physical-server\">#</a></h1>\n<blockquote>\n<p>[!NOTE]</p>\n<h2 id=\"1%2C-singular%2C-decent-machine%2C-estimated-pricing.\">1, singular, decent machine, estimated pricing. <a class=\"heading-anchor-permalink\" href=\"#1%2C-singular%2C-decent-machine%2C-estimated-pricing.\">#</a></h2>\n<p>CPU: A high-performance multi-core processor, such as an Intel Xeon or AMD EPYC server CPU.\nEstimated cost: $2,000 - $5,000</p>\n<hr>\n<p>RAM: At least 128GB to 256GB of RAM to handle multiple concurrent sessions.\nEstimated cost: $1,000 - $2,000</p>\n<hr>\n<p>GPU: A powerful GPU for AI model inference, such as an NVIDIA A100 or A6000.\nEstimated cost: $5,000 - $10,000</p>\n<hr>\n<p>Storage: Fast SSD storage, at least 1TB-2TB for the operating system, AI models, and data.\nEstimated cost: $500 - $1,000</p>\n<hr>\n<p>Server chassis and power supply\nEstimated cost: $1,000 - $2,000</p>\n<hr>\n<p>Total hardware cost estimate: $9,500 - $20,000</p>\n</blockquote>\n<hr>\n<blockquote>\n<p>[!WARNING]\nMy estimate is that this would be fine for up to 100 people at a time. There would be delay.\nMore people = More delay in response as people would be queued up for the next chance the gpu can process the request.</p>\n<ul>\n<li>This means, as a test / first adoption of AI chatbot, one machine would work.\n<ul>\n<li>However, as more use cases and more data is supplied to the chatbot, the more processing power it needs to fulfill the same response times.</li>\n</ul>\n</li>\n</ul>\n</blockquote>\n<blockquote>\n<p>[!important]</p>\n<h2 id=\"if-this-is-the-path-taken%2C-there-are-topics-needed-to-be-handled.\">If this is the path taken, there are topics needed to be handled. <a class=\"heading-anchor-permalink\" href=\"#if-this-is-the-path-taken%2C-there-are-topics-needed-to-be-handled.\">#</a></h2>\n<ol>\n<li>Load balancing.</li>\n</ol>\n<ul>\n<li>If there are multiple machines running the back-end for the chatbot, load balancing will be necessary in order to queue requests</li>\n</ul>\n<ol start=\"2\">\n<li>Linux is the quickest and most cost effective OS.</li>\n</ol>\n<ul>\n<li>Can we handle this with our current security tech stack?</li>\n</ul>\n</blockquote>\n<p>Current docker location: <code>Directory: C:\\Users\\Lochis\\ami-chatbot-db-supabase\\supabase\\docker</code></p>\n<p>Self-hosting Vector DB: Supabase</p>\n<ul>\n<li><a href=\"https://supabase.com/docs/guides/self-hosting/docker\">Instructions</a></li>\n</ul>\n<pre><code class=\"language-bash\"># Stop and remove the containers\n\ndocker compose down\n\n# Recreate and start the containers\n\ndocker compose up -d\n</code></pre>\n<p><a href=\"match_documents.html\">match_documents SQL function for vector similarity search</a></p>\n<blockquote>\n<p>[!IMPORTANT]\nMake sure to enable extension: <strong>Vector</strong> in the <strong>Public Schema</strong></p>\n</blockquote>\n",
      "id": 2
    },
    {
      "path": "match_documents.md",
      "url": "match_documents.html",
      "content": "---\nid: 1721935098-ASZH\naliases:\n  - match_documents SQL function for vector similarity search\ntags: []\n---\n\n# match_documents SQL function for vector similarity search\n\n``` sql\ncreate or replace function match_documents(\n  query_embedding vector(768),\n  match_count int,\n  filter jsonb default '{}'\n)\nreturns table (\n  id integer,\n  content text,\n  metadata jsonb,\n  similarity float\n)\nlanguage plpgsql\nas $$\nbegin\n  return query\n  select\n    documents.id,\n    documents.content,\n    documents.metadata,\n    1 - (documents.embedding <=> query_embedding) as similarity\n  from documents\n  where (filter = '{}' or documents.metadata @> filter)\n  order by documents.embedding <=> query_embedding\n  limit match_count;\nend;\n$$\n;\n\n-- Grant necessary permissions\ngrant execute on function match_documents(vector(768), int, jsonb) to authenticated, anon, service_role;\n```",
      "html": "<hr>\n<p>id: 1721935098-ASZH\naliases:</p>\n<ul>\n<li>match_documents SQL function for vector similarity search\ntags: []</li>\n</ul>\n<hr>\n<h1 id=\"match_documents-sql-function-for-vector-similarity-search\">match_documents SQL function for vector similarity search <a class=\"heading-anchor-permalink\" href=\"#match_documents-sql-function-for-vector-similarity-search\">#</a></h1>\n<pre><code class=\"language-sql\">create or replace function match_documents(\n  query_embedding vector(768),\n  match_count int,\n  filter jsonb default '{}'\n)\nreturns table (\n  id integer,\n  content text,\n  metadata jsonb,\n  similarity float\n)\nlanguage plpgsql\nas $$\nbegin\n  return query\n  select\n    documents.id,\n    documents.content,\n    documents.metadata,\n    1 - (documents.embedding &lt;=&gt; query_embedding) as similarity\n  from documents\n  where (filter = '{}' or documents.metadata @&gt; filter)\n  order by documents.embedding &lt;=&gt; query_embedding\n  limit match_count;\nend;\n$$\n;\n\n-- Grant necessary permissions\ngrant execute on function match_documents(vector(768), int, jsonb) to authenticated, anon, service_role;\n</code></pre>\n",
      "id": 3
    }
  ]
}